import os
import json
import time
from dotenv import load_dotenv
from openai import OpenAI

# ==========================================
# 1. è¨­å®šèˆ‡åˆå§‹åŒ– (Configuration)
# ==========================================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("éŒ¯èª¤ï¼šæœªåµæ¸¬åˆ°ç’°å¢ƒè®Šæ•¸ 'OPENAI_API_KEY'ã€‚")

client = OpenAI(api_key=OPENAI_API_KEY)
MODEL_ID = "gpt-4o-mini"
MODEL_ID = "gpt-4o"

# ã€å„ªåŒ–é»ã€‘å®šç¾©å¸¶æœ‰èªªæ˜çš„åŸå­æ„åœ–
# ä½¿ç”¨å­—å…¸æ ¼å¼ï¼Œæ–¹ä¾¿ LLM ç†è§£æ¯å€‹å·¥å…·çš„ç‰©ç†/è³‡è¨Šæ„ç¾©
KNOWN_ATOMIC_INTENTS = {
    "Move_To(Location)": "Move to a specified location.",
    "Turn(Direction)": "Rotate to a specified direction or angle.",
    "Query_DB(Key)": "Retrieve information from the database.",
    "IoT_Switch(Device_ID, State)": "Control an IoT deviceâ€™s state.",
    "Say(Text)": "Speak or communicate with humans."
}

# ==========================================
# 2. æ ¸å¿ƒ Prompt èˆ‡ API å‘¼å«
# ==========================================

def build_prompt(current_intent):
    # å°‡å­—å…¸è½‰æ›ç‚ºæ˜“è®€çš„æ¸…å–®å­—ä¸²
    tools_description = "\n".join([f"- {k}: {v}" for k, v in KNOWN_ATOMIC_INTENTS.items()])
    
    return f"""
    You are the "GIAS Intent Decomposition Engine". 
    Break down the User Intent into immediate sub-intents (one level deep only).
    
    ### Input Data
    - **Current Intent**: "{current_intent}"
    - **Available Atomic Intents**: [{tools_description}]
    
    ### Rules
    1. One Level Only: Do not decompose recursively in your response. Only identify immediate children.
    2. Atomic Check:
       - Match "Available Atomic Intent" -> mark is_atomic: true, atomic_source: "pre_defined".
       - Specific action NOT in list -> mark is_atomic: true, atomic_source: "new_generated".
       - High-level/Needs more steps -> mark is_atomic: false.
    3. Logical Progress: Ensure the decomposition moves toward solving the problem without diverging.

    ### Output Format
    Return ONLY valid JSON.
    {{
      "parent_intent": "string",
      "sub_intents": [
        {{
          "id": "string",
          "content": "string",
          "is_atomic": boolean,
          "atomic_source": "pre_defined" | "new_generated" | null
        }}
      ],
      "relationships": [
        {{ "type": "Sequence"|"Parallel", "from_id": "...", "to_id": "..." }}
      ]
    }}
    """

def call_llm_decompose(intent):
    try:
        prompt = build_prompt(intent)
        response = client.chat.completions.create(
            model=MODEL_ID,
            messages=[
                {"role": "system", "content": "You are a specialized agent for HTN (Hierarchical Task Network) planning. Output structured JSON for intent decomposition."},
                {"role": "user", "content": prompt}
            ],
            response_format={ "type": "json_object" }
        )
        return json.loads(response.choices[0].message.content.strip())
    except Exception as e:
        print(f"[Error] OpenAI API å‘¼å«å¤±æ•—: {e}")
        return None

# ==========================================
# 3. éè¿´é‚è¼¯ (Hierarchical Task Decomposition)
# ==========================================

def recursive_planner(intent, depth=0, max_depth=8):
    indent = "    " * depth
    prefix = "â””â”€â”€ " if depth > 0 else "[ROOT] "
    print(f"{indent}{prefix}è™•ç†æ„åœ–: {intent}")
    
    if depth >= max_depth:
        print(f"{indent}    [!] é”åˆ°æœ€å¤§æ·±åº¦ï¼Œåœæ­¢æ‹†è§£ã€‚")
        return

    result_json = call_llm_decompose(intent)
    if not result_json:
        return

    sub_intents = result_json.get("sub_intents", [])
    
    for sub in sub_intents:
        content = sub['content']
        is_atomic = sub.get('is_atomic', False)
        source = sub.get('atomic_source')

        if is_atomic:
            marker = "ğŸŸ¢ [EXEC]" if source == "pre_defined" else "ğŸ”´ [NEW]"
            print(f"{indent}    {marker} {content} (Type: {source})")
        else:
            time.sleep(0.1) # é¿é–‹æ¥µçŸ­æ™‚é–“å…§çš„é«˜é »è«‹æ±‚
            recursive_planner(content, depth + 1, max_depth)

# ==========================================
# 4. åŸ·è¡Œå…¥å£
# ==========================================

if __name__ == "__main__":
    root_intent = "åŸ·è¡Œ VIP è¨ªå®¢æ¥å¾…èˆ‡å±•ç¤ºå»³è‡ªå‹•åŒ–å·¡æª¢"
    root_intent = "æº–å‚™ 301 æœƒè­°å®¤ï¼Œä¸‹åˆå…©é»è¦è·Ÿå®¢æˆ¶é€²è¡Œè¦–è¨Šææ¡ˆã€‚"
    
    print("=== GIAS æ„åœ–æ‹†è§£ç³»çµ±å•Ÿå‹• (OpenAI Mode) ===")
    print(f"[ç³»çµ±è³‡è¨Š] ä½¿ç”¨æ¨¡å‹: {MODEL_ID}")
    print("-" * 50)
    
    start_time = time.time()
    recursive_planner(root_intent, max_depth=4)
    
    print("-" * 50)
    print(f"=== æ‹†è§£å®Œæˆï¼Œç¸½è¨ˆç”¨æ™‚: {time.time() - start_time:.2f} ç§’ ===")
