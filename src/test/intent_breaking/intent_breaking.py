import os
import json
import time
from dotenv import load_dotenv
from openai import OpenAI

# ==========================================
# 1. è¨­å®šèˆ‡åˆå§‹åŒ– (Configuration)
# ==========================================
load_dotenv()
# å¾ç’°å¢ƒè®Šæ•¸å–å¾— OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("éŒ¯èª¤ï¼šæœªåµæ¸¬åˆ°ç’°å¢ƒè®Šæ•¸ 'OPENAI_API_KEY'ã€‚")

# åˆå§‹åŒ– OpenAI Client
client = OpenAI(api_key=OPENAI_API_KEY)

# æŒ‡å®šæ¨¡å‹ (å»ºè­°ä½¿ç”¨ gpt-4o æˆ– gpt-4o-mini ä»¥ç²å¾—æœ€ä½³çš„ JSON éµå¾ªèƒ½åŠ›)
MODEL_ID = "gpt-4o-mini"
MODEL_ID = "gpt-4o"

# å®šç¾©ç³»çµ±ç›®å‰æ“æœ‰çš„åŸå­æ„åœ– (GIAS å·²å®šç¾©éƒ¨åˆ†)
KNOWN_ATOMIC_INTENTS = [
    "Move_To(Location)",
    "Turn(Direction)",
    "Query_DB(Key)",
    "IoT_Switch(Device_ID, State)",
    "Say(Text)"
]

# ==========================================
# 2. æ ¸å¿ƒ Prompt èˆ‡ API å‘¼å«
# ==========================================

def build_prompt(current_intent):
    tools_str = ", ".join(KNOWN_ATOMIC_INTENTS)
    return f"""
    You are the "GIAS Intent Decomposition Engine". 
    Break down the User Intent into immediate sub-intents (one level deep only).
    
    ### Input Data
    - **Current Intent**: "{current_intent}"
    - **Available Atomic Intents**: [{tools_str}]
    
    ### Rules
    1. One Level Only: Do not decompose recursively in your response. Only identify immediate children.
    2. Atomic Check:
       - Match "Available Atomic Intent" -> mark is_atomic: true, atomic_source: "pre_defined".
       - Specific action NOT in list -> mark is_atomic: true, atomic_source: "new_generated".
       - High-level/Needs more steps -> mark is_atomic: false.
    3. Logical Progress: Ensure the decomposition moves toward solving the problem without diverging.

    ### Output Format
    Return ONLY valid JSON.
    {{
      "parent_intent": "string",
      "sub_intents": [
        {{
          "id": "string",
          "content": "string",
          "is_atomic": boolean,
          "atomic_source": "pre_defined" | "new_generated" | null
        }}
      ],
      "relationships": [
        {{ "type": "Sequence"|"Parallel", "from_id": "...", "to_id": "..." }}
      ]
    }}
    """

def call_llm_decompose(intent):
    try:
        prompt = build_prompt(intent)
        
        # å‘¼å« OpenAI API
        # ä½¿ç”¨ response_format={ "type": "json_object" } ç¢ºä¿è¼¸å‡ºç‚º JSON
        response = client.chat.completions.create(
            model=MODEL_ID,
            messages=[
                {"role": "system", "content": "You are a helpful assistant that outputs JSON."},
                {"role": "user", "content": prompt}
            ],
            response_format={ "type": "json_object" }
        )
        
        response_text = response.choices[0].message.content.strip()
        
        # è§£æ JSON
        return json.loads(response_text)
    except Exception as e:
        print(f"[Error] OpenAI API å‘¼å«å¤±æ•—: {e}")
        return None

# ==========================================
# 3. éè¿´é‚è¼¯ (Hierarchical Task Decomposition)
# ==========================================

def recursive_planner(intent, depth=0, max_depth=4):
    """
    GIAS éè¿´è¦åŠƒå™¨ï¼šå±¤å±¤æ‹†è§£ç›´åˆ°åŸå­æ„åœ–
    """
    indent = "    " * depth
    prefix = "â””â”€â”€ " if depth > 0 else "[ROOT] "
    print(f"{indent}{prefix}è™•ç†æ„åœ–: {intent}")
    
    if depth >= max_depth:
        print(f"{indent}    [!] é”åˆ°æœ€å¤§æ·±åº¦ï¼Œåœæ­¢æ‹†è§£ã€‚")
        return

    # å–å¾—æœ¬å±¤æ‹†è§£çµæœ
    result_json = call_llm_decompose(intent)
    if not result_json:
        return

    sub_intents = result_json.get("sub_intents", [])
    
    for sub in sub_intents:
        content = sub['content']
        is_atomic = sub.get('is_atomic', False)
        source = sub.get('atomic_source')

        if is_atomic:
            # è‘‰ç¯€é» (Atomic Intent)
            marker = "ğŸŸ¢ [EXEC]" if source == "pre_defined" else "ğŸ”´ [NEW]"
            print(f"{indent}    {marker} {content} (Type: {source})", flush=True)
        else:
            time.sleep(0.2) # ç¨å¾®å»¶é²é¿å…è§¸ç™¼ Rate Limit
            # è¤‡åˆç¯€é» (ç¹¼çºŒéè¿´)
            recursive_planner(content, depth + 1, max_depth)
        

# ==========================================
# 4. åŸ·è¡Œå…¥å£
# ==========================================

if __name__ == "__main__":
    root_intent = "åŸ·è¡Œ VIP è¨ªå®¢æ¥å¾…èˆ‡å±•ç¤ºå»³è‡ªå‹•åŒ–å·¡æª¢"
    root_intent = "æº–å‚™ 301 æœƒè­°å®¤ï¼Œä¸‹åˆå…©é»è¦è·Ÿå®¢æˆ¶é€²è¡Œè¦–è¨Šææ¡ˆã€‚"
    
    print("=== GIAS æ„åœ–æ‹†è§£ç³»çµ±å•Ÿå‹• (OpenAI Mode) ===")
    print(f"[ç³»çµ±è³‡è¨Š] ä½¿ç”¨æ¨¡å‹: {MODEL_ID}")
    print("-" * 50)
    
    start_time = time.time()
    recursive_planner(root_intent, max_depth=5)
    
    print("-" * 50)
    print(f"=== æ‹†è§£å®Œæˆï¼Œç¸½è¨ˆç”¨æ™‚: {time.time() - start_time:.2f} ç§’ ===")


